\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Discussion}\label{chap:discussion}
This thesis started out with two research questions. First, can a 3D CNN be trained to perform the task of nodule detection and second, how can its learned features be extracted and used for understanding the solution? Both questions will be revisited in this final chapter.

\section{A 3DCNN Classifier}
Answering the first research question: it was shown that it is possible to train a network with promising results upon which further optimization could be applied. The performance of the learned network was $81\%$. This is already a better result than reported by Xu et al.~\cite{xu1997development}, Armato et al.~\cite{armato1999computerized}, Lee et al.~\cite{lee2001automated}, Suzuki et al.~\cite{suzuki2003massive} and Teramoto et al.~\cite{teramoto2013fast}. But there are also papers that report higher values, like Cascio et al.~\cite{cascio2012automatic} with a sensitivity of $97\%$. Comparing the false positive rate to the other approaches is a bit more complex since the reference frame changes. Armato~\cite{armato1999computerized} reports, for example, a false positive rate of 3 per slice. Given that the used slices in this thesis have an x,y resolution of $512 \times 512$ and the filter kernel is $50 \times 50 \times 5$, this would result in (depending on how the stride is chosen) $100$ patches per $5$ slices. Assuming that the stride would be chosen in a non-overlapping way this would mean a false positive rate of $2.5$ per slice. This number would rise if the stride would be chosen to jump only one pixel at a time in each direction. The values still show that it is possible to achieve promising results with a pure network architecture. With more time and computational power, it seems possible to find configurations of the network that allow for even better values (as already presented in Section~\ref{sss:struct_changes}). 

Other ways forward include richer augmentation of the samples (rotating by different degrees, flipping the image in the z-direction as well) or including the patches that have been labeled by the radiologists as ``no nodule" as a separate class for training. Other network parameters could be systematically varied and tested for effectiveness, pushing the network performance even further. The same can be done for the training setup: prolonging the time the network has for training, varying the batch size or using a different optimizer for example. One could also think about more radical changes to the infrastructure. What would happen for example if the dense layers are replaced by further convolutional layers, making this a fully convolutional network? Or specifically forcing the network to get rid of unnecessary parameters, by striping down the width and breadth of the layers while maintaining the same functionality. All those considerations can be systematically implemented with little code changes as well as executed and evaluated with the existing training infrastructure.

\section{Understanding the Network}
Answering the second research question proved to be more complicated. The filter kernels could be visualized, but it is hard to define a real measure of similarity to existing approaches and the extracted features did not encode any new or unknown properties of the nodules that could be easily translated into classical features. It still seems possible that this method could reveal deeper insights into other problems. In the same way, this could also reveal deep flaws in the networks way of categorizing samples. Research in the domain of deep neural networks in the realm of natural images shows that they are quite vulnerable to little perturbations in the input space (as for example shown by Su et al.~\cite{su2017one}). The results can also be used to further optimize the network by pruning unnecessary nodes. This can, in turn, make the network more efficient and faster, which enable its use in more production environments. In the case of the presented network, it made sense to get rid of most of the convolutional kernels since the visualization showed their conversion to similar features.

\section{Outlook}
The code for this thesis is completely openly available on \href{https://github.com/AndreaSuckro/acts}{GitHub}\footnote{https://github.com/AndreaSuckro/acts}. It has the necessary documentation available to reproduce the results of this thesis and rich documentation on the code. This allows for other interested researchers to further improve the results and use the code or part of it in an own application. The network could be for example embedded into a complete application, that would take as an input a so far unknown complete CT scan and slide the network over the whole volume, marking in the process the regions that do potentially contain a nodule. An expert radiologist could use the results of the software to guide their own examination of the patient and check whether annotated nodules represent a real threat or are false alarms. Only such a production setting of the algorithm could truly access whether it will help the medical personnel in their decision-making process or not.


% the end :)
\end{document}
